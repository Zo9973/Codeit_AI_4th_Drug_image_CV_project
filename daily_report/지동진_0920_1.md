# Phase 2-3 데이터 증강 및 모델 업그레이드 분석 보고서

## 1. 개요 및 배경

### 1.1 Phase 1 결론 요약
Phase 1에서 신뢰도 임계값 최적화를 통해 다음과 같은 핵심 발견을 했습니다:
- **최적 신뢰도 임계값**: 0.25 확정
- **평가 방식 특성**: Recall 중심 평가 시스템
- **개선 방향**: 임계값 조정의 한계, 구조적 개선 필요성 확인

### 1.2 Phase 2-3 전략 수립
Phase 1의 교훈을 바탕으로 다음과 같은 단계별 접근을 계획했습니다:

**Phase 2 목표: 클래스 불균형 해결**
- 소수 클래스 데이터 증강을 통한 성능 향상
- 목표 성능: 제출 점수 0.958 → 1.05+ (10% 향상)

**Phase 3 목표: 모델 용량 확장**
- RT-DETR-L → RT-DETR-X 업그레이드
- 이미지 해상도 640px → 1024px 증가
- 목표 성능: 1.05+ → 1.15+ (추가 10% 향상)

## 2. Phase 2: 클래스 불균형 해결

### 2.1 실험 설계 및 실행

#### 클래스 분포 분석 결과
**불균형 현황:**
- 총 73개 클래스 중 소수 클래스(<30개 어노테이션) 다수 존재
- 최대/최소 클래스 간 불균형 비율: 약 20:1
- 일부 클래스는 200+ 샘플, 일부는 10개 미만

#### 구현된 개선사항
```python
# 주요 구현 내용
1. 클래스별 분포 자동 분석 함수
2. 소수 클래스 자동 탐지 (30개 미만)
3. 목표 샘플 수까지 데이터 증강 (50개)
4. 증강 기법: 밝기 조정, 색상 변경, 노이즈 추가
```

#### 데이터 증강 결과
- **증강된 클래스**: 소수 클래스 다수
- **생성된 데이터**: +수백 개 이미지 및 어노테이션
- **증강 후 불균형 비율**: 20:1 → 4:1로 개선

### 2.2 Phase 2 실험 결과

#### 정량적 결과
| 지표 | Phase 1 (Baseline) | Phase 2 | 변화 |
|------|-------------------|---------|------|
| **제출 점수** | 0.958 | 0.958 | **0%** |
| **예측 수** | 3,307개 | 3,307개 | **0%** |
| **평균 신뢰도** | 0.412 | 0.412 | **0%** |

#### 핵심 발견사항

**발견 1: 데이터 증강 효과 부재**
- 소수 클래스 증강에도 불구하고 성능 변화 없음
- 예측 결과가 완전히 동일함

**발견 2: 증강 기법의 한계**
- 바운딩 박스 좌표 변경 없는 증강의 제한적 효과
- 간단한 픽셀 레벨 변화만으로는 의미있는 다양성 추가 어려움

**발견 3: 클래스 불균형의 실제 영향**
- 예상과 달리 클래스 불균형이 주요 성능 제약이 아님
- 현재 모델이 소수 클래스도 충분히 학습하고 있을 가능성

### 2.3 Phase 2 실패 원인 분석

#### 기술적 한계
1. **좌표 변환 부재**: 회전, 크롭 등 좌표 변경이 필요한 강력한 증강 미적용
2. **증강 품질**: 밝기/색상 조정만으로는 새로운 패턴 학습 어려움
3. **데이터 다양성**: 기존 이미지의 단순 변형으로는 한계

#### 전략적 오판
1. **문제 진단 오류**: 클래스 불균형을 주요 원인으로 잘못 판단
2. **우선순위 설정**: 데이터 양보다 모델 용량이 더 중요한 제약일 가능성
3. **비용 대비 효과**: 복잡한 증강 구현 대비 효과 미미

## 3. Phase 3: 모델 용량 확장

### 3.1 실험 설계 및 실행

#### 업그레이드 사양
| 구성요소 | Phase 1-2 | Phase 3 | 변화율 |
|----------|-----------|---------|--------|
| **모델 크기** | RT-DETR-L | RT-DETR-X | +33% |
| **이미지 해상도** | 640px | 1024px | +60% |
| **배치 크기** | 8 | 4 | -50% |
| **학습 에포크** | 50 | 100 | +100% |
| **최대 탐지 수** | 100 | 500 | +400% |

#### 학습 환경 및 리소스
- **총 학습 시간**: 11시간 30분
- **GPU 메모리**: 고해상도로 인한 메모리 사용량 증가
- **배치 크기 조정**: 메모리 제약으로 4 → 2로 추가 감소 필요

### 3.2 Phase 3 실험 결과

#### 성능 지표 비교
| 메트릭 | Phase 1-2 | Phase 3 | 변화 | 평가 |
|--------|-----------|---------|------|------|
| **mAP50** | 0.361 | 0.370 | **+2.5%** | 미미한 향상 |
| **mAP50-95** | 0.361 | 0.340 | **-5.8%** | 성능 저하 |
| **Precision** | 0.253 | 0.300 | **+18.6%** | 유일한 개선 |
| **Recall** | 0.995 | 0.900 | **-9.5%** | 심각한 저하 |
| **학습 시간** | 2-3시간 | 11.5시간 | **+383%** | 과도한 증가 |

#### 학습 안정성 분석
- **수렴 양상**: 더 긴 학습에도 불구하고 성능 포화
- **과적합 징후**: 고해상도에서 validation loss 증가 추세
- **학습 효율성**: 시간 대비 성능 향상 매우 비효율적

### 3.3 Phase 3 실패 원인 분석

#### 주요 문제점

**문제 1: 모델 복잡도와 데이터 규모 불균형**
- RT-DETR-X가 현재 데이터셋(73클래스)에 비해 과도한 용량
- 과적합으로 인한 일반화 성능 저하

**문제 2: 고해상도의 역효과**
- 1024px 해상도가 작은 객체에 대해 오히려 노이즈 증가
- 계산 복잡도 급증 대비 성능 향상 미미

**문제 3: 학습 전략 부적절**
- 큰 모델에 적합한 학습률 스케줄링 부재
- 배치 크기 감소로 인한 학습 불안정성

#### 비용 대비 효과 분석
- **리소스 투입**: 11.5시간 (기존 대비 4배)
- **성능 향상**: mAP50 +2.5% (목표 대비 1/4)
- **실용성**: 실제 제출 점수는 오히려 저하 가능성
- **ROI**: 매우 낮은 투자 수익률

## 4. Phase 2-3 종합 평가

### 4.1 실패한 가설들

#### 가설 1: "클래스 불균형이 주요 제약"
**검증 결과**: **거짓**
- 소수 클래스 증강에도 성능 변화 없음
- 현재 모델이 이미 클래스 불균형을 적절히 처리

#### 가설 2: "더 큰 모델이 더 좋은 성능"
**검증 결과**: **부분적 거짓**
- 모델 용량 증가가 오히려 과적합 유발
- 데이터 규모와 모델 복잡도의 균형이 중요

#### 가설 3: "고해상도가 탐지 성능 향상"
**검증 결과**: **거짓**
- 1024px가 640px 대비 실질적 개선 없음
- 계산 비용만 급증

### 4.2 성공한 발견들

#### 발견 1: 현재 모델의 최적화 상태
- RT-DETR-L + 640px + 임계값 0.25가 이미 최적점 근처
- 추가적인 하드웨어 업그레이드보다는 소프트웨어 최적화 필요

#### 발견 2: 평가 시스템의 특성
- Recall 중심 평가에서 Precision 향상은 역효과
- Phase 3에서 Precision 향상(+18.6%)했지만 Recall 저하(-9.5%)로 상쇄

#### 발견 3: 효율성의 중요성
- 11.5시간 학습으로 2.5% 향상은 비실용적
- 빠른 실험과 반복이 더 효과적인 접근

### 4.3 교훈 및 인사이트

#### 방법론적 교훈
1. **단계적 검증**: 각 개선사항을 독립적으로 검증하는 것의 중요성
2. **비용 대비 효과**: 리소스 투입 대비 성능 향상을 사전에 추정
3. **도메인 특성**: 의료 분야에서 Recall의 절대적 중요성

#### 기술적 인사이트
1. **모델 크기 선택**: 데이터 규모에 적합한 모델 선택의 중요성
2. **해상도 최적화**: 무조건 고해상도가 좋은 것은 아님
3. **증강 기법**: 단순한 픽셀 변환보다는 구조적 다양성이 중요

## 5. Phase 4 전략 및 제안

### 5.1 Phase 2-3 실패 분석 기반 전략

#### 새로운 접근 방향
**기존 전략 (실패)**: 하드웨어 업그레이드 중심
- 더 많은 데이터
- 더 큰 모델
- 더 고해상도

**새로운 전략 (제안)**: 소프트웨어 최적화 중심
- 학습 알고리즘 개선
- 앙상블 기법
- 추론 시 최적화

### 5.2 Phase 4 구체적 제안

#### 우선순위 1: TTA (Test Time Augmentation)
**장점**:
- 학습 시간 0시간 (즉시 적용 가능)
- 기존 모델 재활용
- 높은 성능 향상 기대

**구현**:
- 다중 스케일 추론
- 회전/플리핑 앙상블
- 신뢰도 기반 투표

#### 우선순위 2: 하이퍼파라미터 최적화
**개선 영역**:
- 학습률 스케줄링 (Cosine Annealing)
- Loss 함수 개선 (Focal Loss)
- 정규화 기법 강화

#### 우선순위 3: 다중 모델 앙상블
**활용 모델**:
- Phase 1 모델 (RT-DETR-L, 640px)
- Phase 3 모델 (RT-DETR-X, 1024px) - 부분 활용
- 서로 다른 설정의 모델들

### 5.3 예상 성능 향상

| 접근법 | 예상 개선 | 소요 시간 | 난이도 |
|--------|-----------|----------|--------|
| **TTA** | +5-10% | 즉시 | 낮음 |
| **앙상블** | +3-7% | 1-2시간 | 중간 |
| **하이퍼파라미터** | +2-5% | 3-5시간 | 높음 |

## 6. 결론

### 6.1 Phase 2-3 종합 평가
Phase 2와 Phase 3는 **예상과 다른 결과**를 통해 중요한 교훈을 제공했습니다:

**Phase 2 교훈**: 클래스 불균형은 예상보다 중요한 제약이 아니었음
**Phase 3 교훈**: 더 큰 모델이 항상 더 좋은 것은 아님

### 6.2 핵심 발견
1. **현재 모델의 최적화 상태**: RT-DETR-L + 640px + 임계값 0.25가 이미 균형점
2. **평가 시스템 특성**: Recall 중심 평가에서 Precision 향상은 양날의 검
3. **효율성의 중요성**: 11.5시간 투입으로 2.5% 향상은 비실용적

### 6.3 향후 방향
Phase 4에서는 **"스마트한 최적화"**에 집중:
- 하드웨어 업그레이드 대신 소프트웨어 최적화
- 장시간 학습 대신 효율적인 앙상블
- 새로운 데이터 생성 대신 기존 모델 활용 극대화

**핵심 원칙**: "Simple is Better" - 복잡한 해결책보다는 검증된 기법의 조합

---
*작성자: 지동진*  
*분석 기간: 2025년 9월 20일 - 9월 21일*  
*Phase 2-3 완료일: 2025년 9월 21일*  
*다음 단계: Phase 4 소프트웨어 최적화*
